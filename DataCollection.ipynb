{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587aab1c",
   "metadata": {},
   "source": [
    "<h1>Basic Strategy Setup</h1>\n",
    "<h3>Investment Universe: US Equities Listed on NYSE or NASDAQ with daily return less than 5%</h3>\n",
    "<h3>Initial Condition: 1 day return <= -5%</h3>\n",
    "<h3>Holding Period: Enter long position at market close, exit at next day market open</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b24b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "from polygon import RESTClient\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pytz\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import concurrent.futures\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "api_key = 'AKoq4vo8GVYNnuWg9Fw9xv0H93HFXv_m'\n",
    "client = RESTClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b76e15",
   "metadata": {},
   "source": [
    "<h1>(1): Collect dates and corresponding active tickers</h1>\n",
    "<h3>Date range: Jan 2022 - Dec 2023</h3>\n",
    "<h3>Ticker Types: US Equities Listed on NYSE or NASDAQ (no OTC tickers)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36c14fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Dates: 100%|██████████| 1462/1462 [03:25<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dates Count:1006, All Dates Count:1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Date Retrieval\n",
    "all_dates = pd.date_range(start='2020-01-01', end='2024-01-01').strftime('%Y-%m-%d').tolist() #Generate list of all dates in range\n",
    "valid_dates = [] \n",
    "for date in tqdm(all_dates, desc=\"Validating Dates\"): #iterate through all dates, saving any that SPY traded on\n",
    "    response = requests.get(f'https://api.polygon.io/v2/aggs/ticker/SPY/range/1/day/{date}/{date}?adjusted=true&sort=asc&apiKey={api_key}')\n",
    "    if response.json()['queryCount'] == 1:\n",
    "        valid_dates.append(date)\n",
    "print(f'Valid Dates Count:{len(valid_dates)}, All Dates Count:{len(all_dates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1acaef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-03 - 2023-12-29\n"
     ]
    }
   ],
   "source": [
    "#Select Date Range\n",
    "print(f'{valid_dates[505:][0]} - {valid_dates[505:][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a90fce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching tickers: 100%|██████████| 501/501 [05:54<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "#ticker retrieval function: pulls active ticker list\n",
    "def get_tickers(date):\n",
    "    with requests.Session() as s: \n",
    "        response = requests.get(f'https://www.alphavantage.co/query?function=LISTING_STATUS&date={date}&state=active&apikey=UHFFT76TTRPC75V6')\n",
    "        decoded_content = response.content.decode('utf-8')\n",
    "        df = pd.read_csv(StringIO(decoded_content))\n",
    "        tlist = list(df['symbol'])\n",
    "        tlist = [ticker for ticker in tlist if isinstance(ticker, str) and '.' not in ticker and '-' not in ticker and '/' not in ticker]\n",
    "        tlist  = [item for item in tlist if len(item) <= 4]\n",
    "        return tlist\n",
    "\n",
    "ticker_date_dict = {date: get_tickers(date) for date in tqdm(valid_dates[505:], desc=\"Fetching tickers\")}\n",
    "all_unique_tickers = list({ticker for tickers in ticker_date_dict.values() for ticker in tickers}) #get list of all active tickers within date range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2049f",
   "metadata": {},
   "source": [
    "<h1>(2): Scan for daily return less than -5%</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3d21d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10745/10745 [02:51<00:00, 62.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133713 entries, 0 to 133712\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   volume     133713 non-null  float64\n",
      " 1   timestamp  133713 non-null  int64  \n",
      " 2   1d_return  133713 non-null  float64\n",
      " 3   Ticker     133713 non-null  object \n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#collect 1d aggregate data, filter by 1d return <=-5%\n",
    "def daily_aggs(ticker):\n",
    "    try:\n",
    "        #Get daily aggregates\n",
    "        data = client.get_aggs(ticker,\n",
    "                                    multiplier=1,\n",
    "                                    timespan='day',\n",
    "                                    from_='2021-01-01',\n",
    "                                    to='2023-01-01')\n",
    "        df = pd.DataFrame(data)\n",
    "        #Check for data presence, filter OTC tickers\n",
    "        if df.empty or df[df['otc'] != True].empty:\n",
    "            return None\n",
    "        #add identifiers\n",
    "        df['ticker'] = ticker\n",
    "        df['date'] = df['timestamp'].apply(est)\n",
    "        #get 1d return change %, filter by <=-5%, volume >= 50000\n",
    "        df['1d_return'] = round(df['close'].pct_change(),4)\n",
    "        df = df[df['1d_return'] <= -0.05]\n",
    "        df = df[df['volume'] >= 50000]\n",
    "        #Check for data presence post-filter, proceed if possible\n",
    "        if not df.empty:\n",
    "            #format return row(s)\n",
    "            df = df.drop(columns=['open','high','low','close','vwap','otc','transactions'])\n",
    "            #dict->flatten\n",
    "            records_list = df.to_dict(orient='records')\n",
    "            single_dict = records_list if records_list else {}\n",
    "            return single_dict\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    results = list(tqdm(executor.map(daily_aggs, all_unique_tickers), total=len(all_unique_tickers)))\n",
    "\n",
    "results = [item for sublist in results if sublist is not None for item in sublist]\n",
    "basedf = pd.DataFrame(results)\n",
    "basedf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3427252",
   "metadata": {},
   "source": [
    "<h1>(3): Collect Feature and Return Outcome Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616a08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import date processing functions\n",
    "def unix(date_str,hour,minute):\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "    # Define Eastern Standard Time (EST) timezone\n",
    "    est_tz = pytz.timezone('America/New_York')\n",
    "    # Define the time\n",
    "    est_time = datetime(date.year, date.month, date.day, hour, minute, 0)\n",
    "    # Localize the datetime object to EST timezone\n",
    "    est_dt = est_tz.localize(est_time, is_dst=None)\n",
    "    # Convert the datetime object to UTC timezone\n",
    "    utc_dt = est_dt.astimezone(pytz.utc)\n",
    "    # Calculate the Unix timestamp in milliseconds\n",
    "    unix_timestamp_ms = int((utc_dt - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds() * 1000)\n",
    "    return unix_timestamp_ms\n",
    "\n",
    "def est(unix_ms_timestamp):\n",
    "    # Convert Unix timestamp in milliseconds to seconds\n",
    "    unix_seconds = unix_ms_timestamp / 1000.0\n",
    "    # Create a datetime object from the Unix timestamp\n",
    "    utc_time = datetime.utcfromtimestamp(unix_seconds)\n",
    "    # Define the UTC and EST timezones\n",
    "    utc_zone = pytz.utc\n",
    "    est_zone = pytz.timezone('US/Eastern')\n",
    "    # Localize the UTC datetime object to UTC timezone\n",
    "    utc_time = utc_zone.localize(utc_time)\n",
    "    # Convert the UTC time to EST\n",
    "    est_time = utc_time.astimezone(est_zone)\n",
    "    est_time = est_time.replace(tzinfo=None)\n",
    "    return est_time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9438eee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'op_close': 154.5,\n",
       " 'return_target': -0.0125,\n",
       " '1d_intraday_return': 0.0437,\n",
       " '1d_afterhours_return': -0.0185,\n",
       " '2d_return': 0.0624,\n",
       " '3d_return': 0.0708,\n",
       " '4d_return': 0.0804,\n",
       " '5d_return': 0.0587,\n",
       " '6d_return': 0.0732,\n",
       " '7d_return': 0.0891,\n",
       " '8d_return': 0.084,\n",
       " '9d_return': 0.0949,\n",
       " '10d_return': 0.1206,\n",
       " '15d_return': 0.1581,\n",
       " '20d_return': 0.2358}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Daily aggregate-based variable function\n",
    "def daily_vars(ticker,op_date):\n",
    "    try:\n",
    "        ret_dict = {}\n",
    "        #get dates\n",
    "        start_date = valid_dates[valid_dates.index(op_date) - 20] #start 20 days ago\n",
    "        end_date = valid_dates[valid_dates.index(op_date) + 1] #end 1 day ahead\n",
    "\n",
    "        data = client.get_aggs(ticker,\n",
    "                                    multiplier=1,\n",
    "                                    timespan='day',\n",
    "                                    from_=start_date,\n",
    "                                    to=end_date)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['Date'] = df['timestamp'].apply(est)\n",
    "        #check for missing data\n",
    "        if (df[df['Date'] == op_date].empty or df[df['Date'] == end_date].empty or df[df['Date'] == valid_dates[valid_dates.index(op_date) - 1]].empty):\n",
    "            return {}\n",
    "        #create features - close return periods\n",
    "        ret_dict['op_close'] = df[df['Date'] == op_date]['close'].values[0]\n",
    "        ret_dict['return_target'] = round((df[df['Date'] == end_date]['open'].values[0]/ret_dict['op_close'])-1,4)\n",
    "        ret_dict['1d_intraday_return'] = round((ret_dict['op_close']/df[df['Date'] == op_date]['open'].values[0])-1,4) if not df[df['Date'] == op_date].empty else np.nan\n",
    "        ret_dict['1d_afterhours_return']  = round((df[df['Date'] == op_date]['open'].values[0] / df[df['Date'] == valid_dates[valid_dates.index(op_date) - 1]]['close'].values[0]) - 1, 4)\n",
    "        #create features - far return periods\n",
    "        for prevday in [2,3,4,5,6,7,8,9,10,15,20]:\n",
    "            if not df[df['Date'] == valid_dates[valid_dates.index(op_date) - prevday]].empty:\n",
    "                ret_dict[f'{prevday}d_return'] = round((ret_dict['op_close']/df[df['Date'] == valid_dates[valid_dates.index(op_date) - prevday]]['close'].values[0])-1,4)\n",
    "            else:\n",
    "                ret_dict[f'{prevday}d_return'] = np.nan \n",
    "        return ret_dict\n",
    "    except Exception as e:\n",
    "        print(f\"An exception error occurred for {ticker} on {date}: {e}\")\n",
    "        return {}\n",
    "\n",
    "daily_vars('AAPL','2023-02-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c954192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minute aggregate-based variable function\n",
    "def minute_vars(ticker,date_string,op_close):\n",
    "    try:\n",
    "        if np.isnan(op_close):\n",
    "            return {}\n",
    "        \n",
    "        min_dict = {}\n",
    "        #reformat timestamps\n",
    "        start_ts= unix(date_string,14,0)\n",
    "        end_ts = unix(date_string,15,29)\n",
    "        #call API\n",
    "        data = client.get_aggs(ticker,\n",
    "                                    multiplier=1,\n",
    "                                    timespan='minute',\n",
    "                                    from_=start_ts,\n",
    "                                    to=end_ts)\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.empty:\n",
    "            return {}\n",
    "        #2h return\n",
    "        twodf = df[(df['timestamp'] >= unix(date_string,14,0)) & (df['timestamp'] <= unix(date_string,14,29))]\n",
    "        if not twodf.empty:\n",
    "            min_dict['2h_return'] = round((op_close/twodf['open'].iloc[0])-1,4)\n",
    "        else:\n",
    "            min_dict['2h_return'] = np.nan\n",
    "        \n",
    "        #1h return\n",
    "        threedf = df[(df['timestamp'] >= unix(date_string,15,0)) & (df['timestamp'] <= unix(date_string,15,29))]\n",
    "        if not threedf.empty:\n",
    "            min_dict['1h_return'] = round((op_close/threedf['open'].iloc[0])-1,4)\n",
    "        else:\n",
    "            min_dict['1h_return'] = np.nan\n",
    "\n",
    "        return min_dict\n",
    "    except Exception as e:\n",
    "        print(f\"An exception error occurred for {ticker} on {date}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4744f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching tickers:   3%|▎         | 16/501 [09:22<4:44:24, 35.18s/it]\n",
      "100%|██████████| 133713/133713 [27:29<00:00, 81.08it/s] \n",
      "100%|██████████| 133713/133713 [17:35<00:00, 126.67it/s]\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    daily_results = list(tqdm(executor.map(daily_vars, basedf['ticker'], basedf['timestamp']), total=len(basedf)))\n",
    "daily_df = pd.DataFrame(daily_results)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    minute_results = list(tqdm(executor.map(minute_vars, basedf['ticker'], basedf['date'], daily_df['op_close']), total=len(basedf)))\n",
    "minute_df = pd.DataFrame(minute_results)\n",
    "\n",
    "finaldf = pd.concat([basedf, daily_df, minute_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed8eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get spy data\n",
    "spydata = client.get_aggs('SPY',\n",
    "                        multiplier=1,\n",
    "                        timespan='day',\n",
    "                        from_='2021-01-01',\n",
    "                        to='2024-01-01')\n",
    "spydf = pd.DataFrame(spydata)\n",
    "spydf['date'] = spydf['timestamp'].apply(est)\n",
    "spydf['spy_1d_return'] = round(spydf['close'].pct_change(),4)\n",
    "finaldf = finaldf.merge(spydf[['date', 'spy_1d_return']], on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c63ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf['date'] = finaldf['timestamp'].apply(est)\n",
    "finaldf = finaldf.merge(spydf[['date', 'spy_1d_return']], on='date', how='left')\n",
    "finaldf.to_csv('main_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31018ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('main_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
